{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61ca0fa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-06T17:30:54.512590Z",
     "iopub.status.busy": "2025-10-06T17:30:54.512185Z",
     "iopub.status.idle": "2025-10-06T17:30:56.643855Z",
     "shell.execute_reply": "2025-10-06T17:30:56.642608Z"
    },
    "papermill": {
     "duration": 2.138697,
     "end_time": "2025-10-06T17:30:56.645850",
     "exception": false,
     "start_time": "2025-10-06T17:30:54.507153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11550c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:30:56.653224Z",
     "iopub.status.busy": "2025-10-06T17:30:56.652457Z",
     "iopub.status.idle": "2025-10-06T17:31:09.818563Z",
     "shell.execute_reply": "2025-10-06T17:31:09.816985Z"
    },
    "papermill": {
     "duration": 13.171399,
     "end_time": "2025-10-06T17:31:09.820380",
     "exception": false,
     "start_time": "2025-10-06T17:30:56.648981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.2398\n",
      "Epoch 100, Loss: 0.2350\n",
      "Epoch 150, Loss: 0.2336\n",
      "Epoch 200, Loss: 0.2328\n",
      "\n",
      "Prediction:\n",
      "Input: 'i love' -> Next word: pytorch\n",
      "Input: 'love deep' -> Next word: learning\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sample Text\n",
    "\n",
    "text = \"I love deep learning and I love pytorch\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = text.lower().split()\n",
    "vocab = {word: idx for idx, word in enumerate(set(tokens))}\n",
    "rev_vocab = {idx: word for word, idx in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Convert to indices\n",
    "indices = [vocab[w] for w in tokens]\n",
    "\n",
    "# Prepare Dataset\n",
    "seq_len = 2   \n",
    "X, y = [], []\n",
    "\n",
    "for i in range(len(indices) - seq_len):\n",
    "    X.append(indices[i:i+seq_len])   \n",
    "    y.append(indices[i+seq_len])     \n",
    "\n",
    "X = torch.tensor(X)  # shape: (batch, seq_len)\n",
    "y = torch.tensor(y)  # shape: (batch,)\n",
    "\n",
    "# Define RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)                      # (batch, seq_len, embed_dim)\n",
    "        out, hidden = self.rnn(x)              # out: (batch, seq_len, hidden_dim)\n",
    "        out = out[:, -1, :]                   \n",
    "        out = self.fc(out)                     # (batch, vocab_size)\n",
    "        return out\n",
    "\n",
    "# Train Model\n",
    "model = RNNModel(vocab_size, embed_dim=8, hidden_dim=16)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Predict Next Word\n",
    "def predict_next(seq):\n",
    "    model.eval()\n",
    "    seq_idx = torch.tensor([[vocab[w] for w in seq.split()]])\n",
    "    with torch.no_grad():\n",
    "        out = model(seq_idx)\n",
    "        pred_idx = torch.argmax(out, dim=1).item()\n",
    "    return rev_vocab[pred_idx]\n",
    "\n",
    "print(\"\\nPrediction:\")\n",
    "print(\"Input: 'i love' -> Next word:\", predict_next(\"i love\"))\n",
    "print(\"Input: 'love deep' -> Next word:\", predict_next(\"love deep\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccd2d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:31:09.828030Z",
     "iopub.status.busy": "2025-10-06T17:31:09.826959Z",
     "iopub.status.idle": "2025-10-06T17:31:09.843354Z",
     "shell.execute_reply": "2025-10-06T17:31:09.842193Z"
    },
    "papermill": {
     "duration": 0.021648,
     "end_time": "2025-10-06T17:31:09.845040",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.823392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 15, 13,  0,  1,  9,  3,  4,  5,  6,  8,  7, 10, 14, 11])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text=\"My name is Aasif. I am going to be next president of my kingdom. Pray for me\"\n",
    "\n",
    "\n",
    "token=text.lower().split()\n",
    "token\n",
    "type(token)\n",
    "type(set(token))\n",
    "\n",
    "unique={}\n",
    "rev_unique={}\n",
    "for idx, word in enumerate(set(token)):\n",
    "    unique[word]=idx\n",
    "    rev_unique[idx]=word\n",
    "    \n",
    "unique\n",
    "rev_unique\n",
    "\n",
    "indices=[]\n",
    "for i in token:\n",
    "    indices.append(unique[i])\n",
    "indices\n",
    "\n",
    "#make dataset\n",
    "\n",
    "seq_len=2\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in range(len(indices)-seq_len):\n",
    "    x.append(indices[i:i+seq_len])\n",
    "    y.append(indices[i+seq_len])\n",
    "x\n",
    "y\n",
    "\n",
    "x=torch.tensor(x)\n",
    "y=torch.tensor(y)\n",
    "x\n",
    "y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111f80a",
   "metadata": {
    "papermill": {
     "duration": 0.002723,
     "end_time": "2025-10-06T17:31:09.850699",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.847976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9b49e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:31:09.857541Z",
     "iopub.status.busy": "2025-10-06T17:31:09.857134Z",
     "iopub.status.idle": "2025-10-06T17:31:09.863467Z",
     "shell.execute_reply": "2025-10-06T17:31:09.862528Z"
    },
    "papermill": {
     "duration": 0.011881,
     "end_time": "2025-10-06T17:31:09.865299",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.853418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48d4537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:31:09.872622Z",
     "iopub.status.busy": "2025-10-06T17:31:09.872297Z",
     "iopub.status.idle": "2025-10-06T17:31:09.890995Z",
     "shell.execute_reply": "2025-10-06T17:31:09.890021Z"
    },
    "papermill": {
     "duration": 0.024276,
     "end_time": "2025-10-06T17:31:09.892571",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.868295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2204,  1.3315, -0.3567, -0.2629, -0.2053, -1.0809,  0.6216,  1.6743],\n",
       "        [-1.9337,  0.4276, -0.9047,  1.3199, -0.2665, -1.6210,  0.8830,  1.8819],\n",
       "        [ 1.2449, -1.2046,  0.9189,  0.0686,  1.2720, -0.2539, -1.0802,  0.1440]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "text=\"I love cricket very much\"\n",
    "token=text.lower().split()\n",
    "vocab={j:i for i, j in enumerate(set(token))}\n",
    "rev_vocab={i:j for i, j in enumerate(set(token))}\n",
    "unique_total_word=len(set(token))\n",
    "unique_total_word\n",
    "\n",
    "rev_vocab\n",
    "embed_dim=8\n",
    "embedding=nn.Embedding(len(vocab),embed_dim)\n",
    "\n",
    "sample_input=torch.tensor([2,3,1]) # cricket, very, love\n",
    "\n",
    "embed_vector=embedding(sample_input)\n",
    "embed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2d3ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:31:09.900113Z",
     "iopub.status.busy": "2025-10-06T17:31:09.899802Z",
     "iopub.status.idle": "2025-10-06T17:31:09.906850Z",
     "shell.execute_reply": "2025-10-06T17:31:09.905826Z"
    },
    "papermill": {
     "duration": 0.012574,
     "end_time": "2025-10-06T17:31:09.908399",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.895825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'much': 0, 'love': 1, 'i': 2, 'cricket': 3, 'very': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2a9b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T17:31:09.916466Z",
     "iopub.status.busy": "2025-10-06T17:31:09.916083Z",
     "iopub.status.idle": "2025-10-06T17:31:10.503164Z",
     "shell.execute_reply": "2025-10-06T17:31:10.502227Z"
    },
    "papermill": {
     "duration": 0.593557,
     "end_time": "2025-10-06T17:31:10.505140",
     "exception": false,
     "start_time": "2025-10-06T17:31:09.911583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss = 0.0385\n",
      "Epoch 100, Loss = 0.0338\n",
      "Epoch 150, Loss = 0.0326\n",
      "Epoch 200, Loss = 0.0320\n",
      "\n",
      "Input: substantial poverty → Predicted next word: reduction,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# -------------------------\n",
    "# 1. Data Preparation (Corrected)\n",
    "# -------------------------\n",
    "text=\"\"\"Sheikh Hasina Wazed (born September 28, 1947) is a prominent Bangladeshi politician and the daughter of the nation's founding father, Sheikh Mujibur Rahman. She served two separate tenures as the tenth Prime Minister of Bangladesh, first from June 1996 to July 2001, and then for four consecutive terms from January 2009 until her resignation in August 2024, making her the longest-serving head of government in the country's history. Hasina's political career began after surviving the 1975 assassination of her family and returning from exile in 1981 to lead the Awami League political party, spearheading the movement to restore democracy. Her later and longest premiership was credited with overseeing significant economic growth, substantial poverty reduction, and massive infrastructure development (such as the Padma Bridge and Dhaka Metro Rail), alongside the implementation of the \"Digital Bangladesh\" vision. However, her final years in power were marred by increasing international and domestic criticism over allegations of authoritarianism, the erosion of democratic institutions, and suppression of political dissent and human rights abuses, ultimately leading to widespread student-led protests that forced her resignation and flight from the country in August 2024.\"\"\"\n",
    "tokens = text.lower().split()\n",
    "vocab = {word: idx for idx, word in enumerate(set(tokens))}\n",
    "rev_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "indices = [vocab[w] for w in tokens]\n",
    "\n",
    "# dataset বানাই: sequence -> next word\n",
    "seq_len = 2\n",
    "X, y = [], []\n",
    "for i in range(len(indices) - seq_len):\n",
    "    X.append(indices[i:i+seq_len])   # input sequence\n",
    "    y.append(indices[i+seq_len])     # target word\n",
    "\n",
    "# --- FIX APPLIED HERE ---\n",
    "# X and y must be converted to torch.long (integer type) for nn.Embedding\n",
    "X = torch.tensor(X).long()   # shape: (samples, seq_len)\n",
    "y = torch.tensor(y).long()   # shape: (samples,)\n",
    "# ------------------------\n",
    "\n",
    "# -------------------------\n",
    "# 2. RNN Model\n",
    "# -------------------------\n",
    "class RNNPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)                         # [batch, seq_len, embed_dim]\n",
    "        out, h = self.rnn(x)                      # [batch, seq_len, hidden_dim]\n",
    "        out = out[:, -1, :]                       # last timestep only\n",
    "        out = self.fc(out)                        # [batch, vocab_size]\n",
    "        return out\n",
    "\n",
    "# -------------------------\n",
    "# 3. Training\n",
    "# -------------------------\n",
    "vocab_size = len(vocab)\n",
    "model = RNNPredictor(vocab_size, embed_dim=50, hidden_dim=50)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. Prediction Function (Minor change to handle potential unknown words)\n",
    "# -------------------------\n",
    "def predict_next(model, text_seq):\n",
    "    model.eval()\n",
    "    tokens = text_seq.lower().split()\n",
    "    \n",
    "    # Only use words that are in the vocab\n",
    "    idx_seq = [vocab[w] for w in tokens if w in vocab]\n",
    "    \n",
    "    # Check if the sequence length matches the model's seq_len\n",
    "    if len(idx_seq) < seq_len:\n",
    "        print(f\"Error: Input sequence needs at least {seq_len} known words.\")\n",
    "        return \"N/A\"\n",
    "        \n",
    "    idx_seq = idx_seq[-seq_len:] # Use only the last seq_len tokens\n",
    "    \n",
    "    # --- FIX APPLIED HERE ---\n",
    "    # The input tensor must also be cast to torch.long\n",
    "    idx_seq = torch.tensor(idx_seq).unsqueeze(0).long()  # [1, seq_len], ensuring long type\n",
    "    # ------------------------\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(idx_seq)\n",
    "        pred_idx = torch.argmax(out, dim=1).item()\n",
    "    return rev_vocab[pred_idx]\n",
    "\n",
    "# -------------------------\n",
    "# 5. Test Prediction\n",
    "# -------------------------\n",
    "# You must use a sequence that is in your vocabulary (since there is no OOV handling)\n",
    "# \"bangladeshi politician\" are two tokens found in your text\n",
    "test_seq = \"substantial poverty\" \n",
    "pred_word = predict_next(model, test_seq)\n",
    "print(f\"\\nInput: {test_seq} → Predicted next word: {pred_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33c2b1",
   "metadata": {
    "papermill": {
     "duration": 0.002806,
     "end_time": "2025-10-06T17:31:10.511219",
     "exception": false,
     "start_time": "2025-10-06T17:31:10.508413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.025197,
   "end_time": "2025-10-06T17:31:13.241423",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-06T17:30:48.216226",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
